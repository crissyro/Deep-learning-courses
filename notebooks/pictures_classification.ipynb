{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/crissyro/Deep-learning-courses/blob/main/notebooks/pictures_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f2a2e90",
      "metadata": {
        "id": "0f2a2e90"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import warnings\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from torch import nn, optim\n",
        "from torchvision import transforms as transforms\n",
        "from IPython.display import clear_output\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa7e6243",
      "metadata": {
        "id": "aa7e6243",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "elif torch.has_mps:\n",
        "    device = torch.device('mps')\n",
        "else:\n",
        "    device = torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "696b0cfd",
      "metadata": {
        "id": "696b0cfd"
      },
      "outputs": [],
      "source": [
        "transforms_ = transforms.Compose(\n",
        "    [\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
        "    ]\n",
        ")\n",
        "\n",
        "cifar_train = torchvision.datasets.CIFAR10(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transforms_\n",
        ")\n",
        "\n",
        "cifar_test = torchvision.datasets.CIFAR10(\n",
        "    root='./data',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transforms_\n",
        ")\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    cifar_train,\n",
        "    batch_size=128,\n",
        "    shuffle=True,\n",
        "    num_workers=4\n",
        ")\n",
        "\n",
        "test_dataloader = torch.utils.data.DataLoader(\n",
        "    cifar_test,\n",
        "    batch_size=128,\n",
        "    shuffle=False,\n",
        "    num_workers=4\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def image_show(img, one_channel=False):\n",
        "  if one_channel:\n",
        "    img = img.mean(dim=0)\n",
        "\n",
        "  img = img / 2 + 0.5\n",
        "  np_img = img.numpy()\n",
        "  if one_channel:\n",
        "    plt.imshow(np_img, cmap='Greys')\n",
        "  else:\n",
        "    plt.imshow(np.transpose(np_img, (1, 2, 0)))"
      ],
      "metadata": {
        "id": "bFnxQ4Co3W4U"
      },
      "id": "bFnxQ4Co3W4U",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = next(iter(train_dataloader))\n",
        "\n",
        "img_grid = torchvision.utils.make_grid(image)\n",
        "\n",
        "plt.figure(figsize=(15, 15))\n",
        "image_show(img_grid)"
      ],
      "metadata": {
        "id": "P3bO_mbA4GEP"
      },
      "id": "P3bO_mbA4GEP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_history(train_loss, test_loss, train_acc, test_acc):\n",
        "    sns.set_style(\"whitegrid\")\n",
        "    plt.figure(figsize=(16, 6), dpi=100)\n",
        "\n",
        "    plot_params = {\n",
        "        'linewidth': 2,\n",
        "        'markersize': 8,\n",
        "        'alpha': 0.8\n",
        "    }\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(train_loss, label='Train',\n",
        "             color='#1f77b4', marker='o', **plot_params)\n",
        "    plt.plot(test_loss, label='Validation',\n",
        "             color='#ff7f0e', marker='s', linestyle='--', **plot_params)\n",
        "    plt.title('Loss Evolution', fontsize=14, pad=12)\n",
        "    plt.xlabel('Epoch', fontsize=12)\n",
        "    plt.ylabel('Loss', fontsize=12)\n",
        "    plt.xticks(np.arange(0, len(train_loss)))\n",
        "    plt.legend(fontsize=12)\n",
        "    plt.grid(alpha=0.3)\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(train_acc, label='Train',\n",
        "             color='#1f77b4', marker='o', **plot_params)\n",
        "    plt.plot(test_acc, label='Validation',\n",
        "             color='#ff7f0e', marker='s', linestyle='--', **plot_params)\n",
        "    plt.title('Accuracy Evolution', fontsize=14, pad=12)\n",
        "    plt.xlabel('Epoch', fontsize=12)\n",
        "    plt.ylabel('Accuracy', fontsize=12)\n",
        "    plt.xticks(np.arange(0, len(train_acc)))\n",
        "    plt.ylim(0, 1.05)\n",
        "    plt.yticks(np.linspace(0, 1, 5))\n",
        "    plt.legend(fontsize=12)\n",
        "    plt.grid(alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "FlruNbO74LBj"
      },
      "id": "FlruNbO74LBj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VGG(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.vgg = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1),\n",
        "        nn.LeakyReLU(),\n",
        "        nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, padding=1),\n",
        "        nn.LeakyReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "    )\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.fc = nn.Sequential(\n",
        "        nn.Linear(in_features=16 * 16 * 16, out_features=128),\n",
        "        nn.LeakyReLU(),\n",
        "        nn.Linear(in_features=128, out_features=10)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.vgg(x)\n",
        "    x = self.flatten(x)\n",
        "    x = self.fc(x)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "s9u862Oh6DMb"
      },
      "id": "s9u862Oh6DMb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, criterion, optimizer, train_loader, val_loader, n_epochs=10):\n",
        "    train_loss, train_acc = [], []\n",
        "    val_loss, val_acc = [], []\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        model.train()\n",
        "        epoch_train_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with tqdm(train_loader, unit=\"batch\", desc=f'Epoch {epoch+1}/{n_epochs} [Train]') as pbar:\n",
        "            for inputs, labels in pbar:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                batch_size = labels.size(0)\n",
        "                epoch_train_loss += loss.item() * batch_size\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "                total += batch_size\n",
        "\n",
        "                pbar.set_postfix({\n",
        "                    'loss': f\"{loss.item():.4f}\",\n",
        "                    'acc': f\"{correct/total:.3f}\"\n",
        "                })\n",
        "\n",
        "        train_loss.append(epoch_train_loss / total)\n",
        "        train_acc.append(correct / total)\n",
        "\n",
        "        model.eval()\n",
        "        epoch_val_loss = 0.0\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                batch_size = labels.size(0)\n",
        "                epoch_val_loss += loss.item() * batch_size\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                val_correct += (predicted == labels).sum().item()\n",
        "                val_total += batch_size\n",
        "\n",
        "        val_loss.append(epoch_val_loss / val_total)\n",
        "        val_acc.append(val_correct / val_total)\n",
        "\n",
        "        clear_output(wait=True)\n",
        "        plot_history(train_loss, val_loss, train_acc, val_acc)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{n_epochs}\")\n",
        "        print(f\"Train Loss: {train_loss[-1]:.4f} | Train Acc: {train_acc[-1]:.4f}\")\n",
        "        print(f\" Val Loss: {val_loss[-1]:.4f} |  Val Acc: {val_acc[-1]:.4f}\")\n",
        "        print(\"-\" * 60)\n",
        "\n",
        "    return model, (train_loss, val_loss, train_acc, val_acc)"
      ],
      "metadata": {
        "id": "TOW8hdhEA01m"
      },
      "id": "TOW8hdhEA01m",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = VGG().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "md, history = train(model, criterion, optimizer, train_dataloader, test_dataloader, n_epochs=5)\n",
        "\n",
        "md, history"
      ],
      "metadata": {
        "id": "AuhJof9cDyRg"
      },
      "id": "AuhJof9cDyRg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "import PIL\n",
        "\n",
        "transforms_ = transforms.Compose(\n",
        "    [\n",
        "    transforms.ColorJitter(hue=0.05, saturation=0.05),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
        "    ]\n",
        ")\n",
        "\n",
        "base_transforms = transforms.Compose(\n",
        "    [\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
        "    ]\n",
        ")\n",
        "\n",
        "cifar_train = torchvision.datasets.CIFAR10(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transforms_\n",
        ")\n",
        "\n",
        "cifar_val = torchvision.datasets.CIFAR10(\n",
        "    root='./data',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=base_transforms\n",
        ")\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    cifar_train,\n",
        "    batch_size=128,\n",
        "    shuffle=True,\n",
        "    num_workers=4\n",
        ")\n",
        "\n",
        "val_dataloader = torch.utils.data.DataLoader(\n",
        "    cifar_val,\n",
        "    batch_size=128,\n",
        "    shuffle=False,\n",
        "    num_workers=4\n",
        ")"
      ],
      "metadata": {
        "id": "47gToRLdETU2",
        "cellView": "form"
      },
      "id": "47gToRLdETU2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = next(iter(train_dataloader))\n",
        "\n",
        "img_grid = torchvision.utils.make_grid(image)\n",
        "\n",
        "plt.figure(figsize=(15, 15))\n",
        "image_show(img_grid)"
      ],
      "metadata": {
        "id": "UBAFhqXJQCYr"
      },
      "id": "UBAFhqXJQCYr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = VGG().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "train(model, criterion, optimizer, train_dataloader, test_dataloader, n_epochs=7)"
      ],
      "metadata": {
        "id": "NCNUL1OJQHk8"
      },
      "id": "NCNUL1OJQHk8",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "private_outputs": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}